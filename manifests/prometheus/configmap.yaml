---
# Prometheus ConfigMap
# Contains prometheus.yml configuration and alerting rules
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
  labels:
    app: prometheus
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/component: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      scrape_timeout: 10s
      evaluation_interval: 15s
      external_labels:
        cluster: 'vmstation-homelab'
        environment: 'homelab'
      
    # Alerting configuration
    alerting:
      alertmanagers:
      - static_configs:
        - targets: []
    
    # Load alerting rules
    rule_files:
    - /etc/prometheus/rules/*.yml
    
    scrape_configs:
    # Kubernetes API server metrics
    - job_name: 'kubernetes-apiservers'
      kubernetes_sd_configs:
      - role: endpoints
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: default;kubernetes;https
        
    # Kubernetes node kubelet metrics
    - job_name: 'kubernetes-nodes'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics
        
    # Container metrics via cAdvisor
    - job_name: 'kubernetes-cadvisor'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      metrics_path: /metrics/cadvisor
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor
    
    # Node Exporter - All nodes
    # NOTE: These IP addresses are specific to the VMStation homelab environment.
    # For other deployments, update the targets or use Kustomize overlays.
    # Consider using Kubernetes service discovery for dynamic environments.
    - job_name: 'node-exporter'
      static_configs:
      - targets:
        - '192.168.4.63:9100'  # masternode (Debian control-plane)
        labels:
          node: 'masternode'
          role: 'control-plane'
          os: 'debian'
      - targets:
        - '192.168.4.61:9100'  # storagenodet3500 (Debian worker)
        labels:
          node: 'storagenodet3500'
          role: 'storage'
          os: 'debian'
      - targets:
        - '192.168.4.62:9100'  # homelab (RHEL 10 worker)
        labels:
          node: 'homelab'
          role: 'compute'
          os: 'rhel10'
    
    # IPMI Exporter - Enterprise server (homelab RHEL 10 node)
    - job_name: 'ipmi-exporter'
      static_configs:
      - targets:
        - '192.168.4.62:9290'  # IPMI exporter on homelab node
        labels:
          node: 'homelab'
          role: 'compute'
          os: 'rhel10'
          hardware: 'enterprise-server'
      metrics_path: /metrics
      scrape_interval: 30s
      scrape_timeout: 20s
    
    # Remote IPMI Exporter - Enterprise server at 192.168.4.60
    - job_name: 'ipmi-exporter-remote'
      static_configs:
      - targets:
        - '192.168.4.60'  # Remote enterprise server BMC address
        labels:
          node: 'enterprise-server-60'
          role: 'enterprise-compute'
          hardware: 'enterprise-server'
      metrics_path: /metrics
      scrape_interval: 30s
      scrape_timeout: 20s
      relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: ipmi-exporter-remote.monitoring.svc.cluster.local:9291
    
    # Kube State Metrics - Kubernetes object state
    - job_name: 'kube-state-metrics'
      kubernetes_sd_configs:
      - role: service
        namespaces:
          names:
          - monitoring
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name]
        action: keep
        regex: kube-state-metrics
      - source_labels: [__meta_kubernetes_service_port_name]
        action: keep
        regex: http-metrics
    
    # Prometheus self-monitoring
    - job_name: 'prometheus'
      static_configs:
      - targets:
        - 'localhost:9090'
    
    # Service endpoints
    - job_name: 'kubernetes-service-endpoints'
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
        action: replace
        target_label: __scheme__
        regex: (https?)
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_service_name]
        action: replace
        target_label: kubernetes_name

    # Blackbox exporter - network / DNS / HTTP probes
    - job_name: 'blackbox'
      metrics_path: /probe
      params:
        module: [http_2xx]
      static_configs:
      - targets:
        - http://prometheus.monitoring.svc.cluster.local:9090/-/healthy
        - http://grafana.monitoring.svc.cluster.local:3000/api/health
        - http://loki.monitoring.svc.cluster.local:3100/ready
        - https://1.1.1.1
        - https://8.8.8.8
      relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: blackbox-exporter.monitoring.svc.cluster.local:9115
    
    # RKE2 Federation - Federate metrics from RHEL 10 homelab RKE2 cluster
    - job_name: 'rke2-federation'
      honor_labels: true
      metrics_path: /federate
      params:
        'match[]':
        - '{job=~".+"}'
      static_configs:
      - targets:
        - '192.168.4.62:30090'
        labels:
          cluster: 'rke2-homelab'
          federated: 'true'
    
    # Homelab Node Exporter - Direct scrape from RHEL 10 node
    - job_name: 'homelab-node-exporter'
      static_configs:
      - targets:
        - '192.168.4.62:9100'
        labels:
          node: 'homelab'
          cluster: 'rke2-homelab'
          instance: '192.168.4.62:9100'
    
    # Chrony NTP Exporter - Time synchronization monitoring
    - job_name: 'chrony-ntp'
      kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
          - infrastructure
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        action: keep
        regex: chrony-ntp
      - source_labels: [__meta_kubernetes_pod_container_port_name]
        action: keep
        regex: metrics
      - source_labels: [__meta_kubernetes_pod_node_name]
        target_label: node
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: pod
    
    # Syslog Server Metrics - Log aggregation monitoring
    - job_name: 'syslog-server'
      kubernetes_sd_configs:
      - role: service
        namespaces:
          names:
          - infrastructure
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name]
        action: keep
        regex: syslog-server
      - source_labels: [__meta_kubernetes_service_port_name]
        action: keep
        regex: metrics
---
# Prometheus Alerting Rules
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  namespace: monitoring
  labels:
    app: prometheus
    app.kubernetes.io/name: prometheus
data:
  alerts.yml: |
    groups:
    - name: node-health.rules
      interval: 30s
      rules:
      - alert: NodeExporterDown
        expr: up{job="node-exporter"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: Node exporter down on {{ $labels.instance }}
          description: Node exporter has been unreachable for more than 2 minutes.
      - alert: HighNodeCPU
        expr: (100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: High CPU usage on {{ $labels.instance }}
          description: Node CPU usage > 85% for 5m.
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 90
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: High memory usage on {{ $labels.instance }}
          description: Memory usage > 90% for 5m.
    - name: dns-network.rules
      interval: 1m
      rules:
      - alert: CoreDNSDown
        expr: sum(up{job="kubernetes-service-endpoints", kubernetes_name="kube-dns"}) == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: CoreDNS appears down
          description: No CoreDNS endpoints responding for 2 minutes.
      - alert: BlackboxProbeFailed
        expr: probe_success == 0
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: Blackbox probe failed for {{ $labels.instance }}
          description: Network probe to {{ $labels.instance }} failing.
    
    - name: time-sync.rules
      interval: 1m
      rules:
      - alert: NTPServiceDown
        expr: up{job="chrony-ntp"} == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: NTP service down on {{ $labels.node }}
          description: Chrony NTP exporter has been down for 5 minutes on {{ $labels.node }}. Time drift may occur.
      - alert: HighTimeOffset
        expr: abs(chrony_tracking_last_offset_seconds) > 0.5
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: High time offset on {{ $labels.node }}
          description: System time offset is {{ $value }}s on {{ $labels.node }}. Expected < 0.5s.
      - alert: NTPNotSynchronized
        expr: chrony_tracking_stratum > 10
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: NTP not synchronized on {{ $labels.node }}
          description: NTP stratum is {{ $value }} (expected <= 10) on {{ $labels.node }}. Time source may be unreachable.
    
    - name: logging.rules
      interval: 1m
      rules:
      - alert: SyslogServerDown
        expr: up{job="syslog-server"} == 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: Syslog server is down
          description: Centralized syslog server has been unreachable for 5 minutes.
      - alert: HighSyslogMessageRate
        expr: rate(syslog_messages_total[5m]) > 1000
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: High syslog message rate
          description: "Syslog server receiving {{ $value }} messages/sec (threshold: 1000/sec)."
    
    - name: monitoring.rules
      interval: 1m
      rules:
      - alert: PrometheusTargetsDown
        expr: (count(up == 0) BY (job) / count(up) BY (job)) > 0.3
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: More than 30% of {{ $labels.job }} targets are down
          description: "{{ $value | humanizePercentage }} of {{ $labels.job }} targets are down."
      - alert: PrometheusTSDBReloadsFailing
        expr: increase(prometheus_tsdb_reloads_failures_total[3h]) > 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: Prometheus TSDB reloads are failing
          description: Prometheus had {{ $value }} reload failures in the last 3 hours.
      - alert: PrometheusConfigReloadFailed
        expr: prometheus_config_last_reload_successful == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: Prometheus configuration reload failed
          description: Prometheus config reload has failed. Check logs for details.
